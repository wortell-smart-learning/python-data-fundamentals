{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie scraping script: enrich my basic movie data with some extra info by scraping IMDB\n",
    "## Extra movie info such as country, language, budget etc.\n",
    "## The scraping is done with beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "pd.options.display.max_colwidth = 50\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('most_voted_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get and parse html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_of_html_page(url):\n",
    "    \"\"\"\n",
    "    Takes a url and does a request to get the html page.\n",
    "    The html pages gets processed into a beautiful soup object.\n",
    "    \"\"\"\n",
    "    html_page = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small functions to save (and load) intermediate scraping results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_obj(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to pick out interesting info from a movie page, such as country, language, budget etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_details(title_id):\n",
    "    \"\"\"Uses a title_id from imdb to scrape the page of that movie and return\n",
    "    details of that movie such as the summary text, country, language,\n",
    "    metascore etc.\"\"\"\n",
    "    \n",
    "    soup_page = get_soup_of_html_page(f'https://www.imdb.com/title/{title_id}/')\n",
    "\n",
    "    try:\n",
    "        metascore = soup_page.find('div', class_='titleReviewBar').select_one(\"a[href*=criticreviews]\").text.strip()\n",
    "    except: \n",
    "        metascore = ''\n",
    "    \n",
    "    try:\n",
    "        image_url = soup_page.find('img')['src']\n",
    "    except:\n",
    "        image_url = ''\n",
    "        \n",
    "    try:\n",
    "        summary = soup_page.find('div', class_='summary_text').text.strip()\n",
    "    except:\n",
    "        summary = ''\n",
    "\n",
    "    try:\n",
    "        country = soup_page.find('div', id='titleDetails').select_one(\"a[href*=country]\").text.strip()\n",
    "    except:\n",
    "        country = ''\n",
    "        \n",
    "    try:\n",
    "        primary_language = soup_page.find('div', id='titleDetails').select_one(\"a[href*=language]\").text.strip()\n",
    "    except:\n",
    "        primary_language = ''\n",
    "        \n",
    "    try:\n",
    "        color = soup_page.find('div', id='titleDetails').select_one(\"a[href*=color]\").text.strip()\n",
    "    except:\n",
    "        color = ''\n",
    "\n",
    "        \n",
    "    try:\n",
    "        tagline_rawtext = soup_page.find('div', id=\"titleStoryLine\").find('div', class_='txt-block').text\n",
    "        if 'Taglines:' in tagline_rawtext:\n",
    "            tagline = re.sub('.*(See more.*)', '', tagline_rawtext).replace('Taglines:', '').strip()\n",
    "        else:\n",
    "            tagline = ''\n",
    "    except:\n",
    "        tagline = ''\n",
    "            \n",
    "\n",
    "    try:\n",
    "        tagline_rawtext = soup_page.find('div', id=\"titleDetails\").text #.replace('\\n', '')\n",
    "        \n",
    "        if 'Budget:' in tagline_rawtext:\n",
    "            budget_text = re.sub('.*Budget:','', tagline_rawtext, flags=re.DOTALL)\n",
    "            budget_text = re.sub('\\n.*', '', budget_text, flags=re.DOTALL).strip()\n",
    "        else:\n",
    "            budget_text = ''\n",
    "            \n",
    "        if 'Cumulative Worldwide Gross:' in tagline_rawtext:\n",
    "            cumulative_text = re.sub('.*Cumulative Worldwide Gross:','', tagline_rawtext, flags=re.DOTALL)\n",
    "            cumulative_text = re.sub('\\n.*', '', cumulative_text, flags=re.DOTALL).strip()\n",
    "            \n",
    "        else:\n",
    "            cumulative_text = ''\n",
    "            \n",
    "        if 'Opening Weekend USA:' in tagline_rawtext:\n",
    "            opening_weekend_usa = re.sub('.*Opening Weekend USA:', '', tagline_rawtext, flags=re.DOTALL)\n",
    "            opening_weekend_usa = re.sub('\\n.*', '', opening_weekend_usa, flags=re.DOTALL).strip()\n",
    "        else:\n",
    "            opening_weekend_usa = ''\n",
    "            \n",
    "        if 'Gross USA:' in tagline_rawtext:\n",
    "            gross_usa = re.sub('.*Gross USA:','', tagline_rawtext, flags=re.DOTALL)\n",
    "            gross_usa = re.sub('\\n.*', '', gross_usa, flags=re.DOTALL).strip()\n",
    "        else:\n",
    "            gross_usa = ''\n",
    "        \n",
    "    except:\n",
    "        budget_text = ''\n",
    "        cumulative_text = ''\n",
    "        opening_weekend_usa = ''\n",
    "        gross_usa = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    title_details =  {\n",
    "        'tconst': title_id,\n",
    "        'metascore': metascore,\n",
    "        'country': country,\n",
    "        'primary_language': primary_language,\n",
    "        'color': color,\n",
    "        'budget': budget_text,\n",
    "        'opening_weekend_usa': opening_weekend_usa,\n",
    "        'gross_usa': gross_usa,\n",
    "        'cumulative_worldwide': cumulative_text,\n",
    "        'tagline': tagline,\n",
    "        'summary': summary,\n",
    "        'image_url': image_url,\n",
    "    }\n",
    "    \n",
    "    return title_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start scraping and save every 100 movies scraped to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "\n",
    "for number, title_id in enumerate(df['tconst']):\n",
    "    result_dict[number] = get_title_details(title_id)\n",
    "    \n",
    "    if number%100==0 and number != 0:\n",
    "        print(number)\n",
    "        save_obj(result_dict, f'imdb_{str(number).zfill(7)}_scrape.pkl')\n",
    "        result_dict = {}\n",
    "\n",
    "print(number)\n",
    "save_obj(result_dict, f'imdb_{str(number).zfill(7)}_scrape.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put all intermediate results together again in 1 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_files = [file_name for file_name in os.listdir() if 'pkl' in file_name]\n",
    "\n",
    "pickled_dfs = [pd.DataFrame.from_dict(load_obj(file_name), orient='index') for file_name in pickle_files]\n",
    "\n",
    "df_all_movies_scraped = pd.concat(pickled_dfs).sort_index()\n",
    "\n",
    "df_all_movies_scraped.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_movies_scraped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the original dataframe with the extra info we scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_all_movies_scraped, on='tconst', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['budget'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the results to a new datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('most_voted_titles_enriched.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hv_new",
   "language": "python",
   "name": "hv_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
